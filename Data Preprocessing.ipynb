{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a2992",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14a1ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162980 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162976 non-null  object \n",
      " 1   category    162973 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Twitter_Data.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd585787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8b92fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162980, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52ad362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    4\n",
       "category      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3279caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07793c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    0\n",
       "category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdb395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples\n"
     ]
    }
   ],
   "source": [
    "print(dataset['clean_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b125f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(dataset['clean_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1bab3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea2e54",
   "metadata": {},
   "source": [
    "# Step 0: Counting entries of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1497c74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    72249\n",
       " 0.0    55211\n",
       "-1.0    35509\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = dataset['category'].value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8bb1a2",
   "metadata": {},
   "source": [
    "## Undersampling to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5758742",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 30000\n",
    "\n",
    "# Undersample each class to the size of the smallest class\n",
    "df_neutral = dataset[dataset['category'] == 0].sample(min_count, random_state=42)\n",
    "df_positive = dataset[dataset['category'] == 1].sample(min_count, random_state=42)\n",
    "df_negative = dataset[dataset['category'] == -1].sample(min_count, random_state=42)\n",
    "\n",
    "# Combine the undersampled data\n",
    "df_balanced = pd.concat([df_neutral, df_positive, df_negative])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "dataset = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca743c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4662d625",
   "metadata": {},
   "source": [
    "# Step 1: Lower Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e028c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(data):\n",
    "    clean_text_1 = []\n",
    "    for sentence in data:\n",
    "        clean_text_1.append(str.lower(sentence))\n",
    "    return clean_text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd8462f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modi will due day but before that will make india bankrupt',\n",
       " 'talks about the another tweet saying too close call bjp mgb bjp con concludes modi name prevails bjp wil otherwise ',\n",
       " 'thanks for information  thanks this series will see the true stoties and india',\n",
       " 'watch they used want send each other jail modi takes spbsp alliance harkens back their past ',\n",
       " 'modi waiting for min 50k likes giis tweet its already past due time ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_1 = to_lower(dataset['clean_text'])\n",
    "clean_text_1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb793df",
   "metadata": {},
   "source": [
    "# Step 2: Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6277fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(data):\n",
    "    clean_text_2 = [word_tokenize(i) for i in data]\n",
    "    return clean_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66a8b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_2 = tokenize_sentence(clean_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b56d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['modi', 'will', 'due', 'day', 'but', 'before', 'that', 'will', 'make', 'india', 'bankrupt']]\n"
     ]
    }
   ],
   "source": [
    "print(clean_text_2[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff190685",
   "metadata": {},
   "source": [
    "# Step 3 : punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37b64acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    clean_text_3 = []\n",
    "\n",
    "    for words in text:\n",
    "        clean = []\n",
    "        for w in words:\n",
    "            res = re.sub(r'[^\\w\\s]', \"\", w)\n",
    "            if res != \"\":\n",
    "                clean.append(res)\n",
    "        clean_text_3.append(clean)\n",
    "    return clean_text_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c52f132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['modi', 'waiting', 'for', 'min', '50k', 'likes', 'giis', 'tweet', 'its', 'already', 'past', 'due', 'time']]\n"
     ]
    }
   ],
   "source": [
    "clean_text_3 = remove_punctuation(clean_text_2)\n",
    "print(clean_text_3[4:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dbef1",
   "metadata": {},
   "source": [
    "# Step 4: stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c359f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    clean_text_4 = []\n",
    "\n",
    "    for words in text:\n",
    "        clean = []\n",
    "        for word in words:\n",
    "            if not word in stopwords.words('english'):\n",
    "                clean.append(word)\n",
    "        clean_text_4.append(clean)\n",
    "    return clean_text_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0e035d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "6\n",
      "[['modi', 'due', 'day', 'make', 'india', 'bankrupt']]\n"
     ]
    }
   ],
   "source": [
    "clean_text_4 = remove_stopwords(clean_text_3)\n",
    "print(len(clean_text_3[0]))\n",
    "print(len(clean_text_4[0]))\n",
    "print(clean_text_4[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77e6a3",
   "metadata": {},
   "source": [
    "# Stage 5: Stemming Or Lemitizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8092e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer_sentence(text):\n",
    "    port = PorterStemmer()\n",
    "    clean_text_5 = []\n",
    "\n",
    "    for words in text:\n",
    "        clean = [port.stem(word) for word in words]\n",
    "        clean_text_5.append(clean)\n",
    "    return clean_text_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c232fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['modi', 'due', 'day', 'make', 'india', 'bankrupt']]\n"
     ]
    }
   ],
   "source": [
    "clean_text_5 = stemmer_sentence(clean_text_4)\n",
    "print(clean_text_5[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f918ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_lematizer(text):\n",
    "    wnet = WordNetLemmatizer()\n",
    "    clean_text_6 = []\n",
    "\n",
    "    for words in text:\n",
    "        clean = [wnet.lemmatize(word) for word in words]\n",
    "        clean_text_6.append(clean)\n",
    "    return clean_text_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de042b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_6 = sentence_lematizer(clean_text_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7aaea87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['modi', 'waiting', 'min', '50k', 'like', 'giis', 'tweet', 'already', 'past', 'due', 'time']]\n"
     ]
    }
   ],
   "source": [
    "print(clean_text_6[4:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40443742",
   "metadata": {},
   "source": [
    "# Stage 6: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "014e2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text):\n",
    "    clean_text_6_as_strings = [' '.join(words) for words in text]\n",
    "\n",
    "    # Convert text data into TF-IDF features\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "    X = vectorizer.fit_transform(clean_text_6_as_strings)\n",
    "    \n",
    "    joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe07ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorize(clean_text_6)\n",
    "# Convert the target variable to numerical values\n",
    "y = dataset['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9931e07",
   "metadata": {},
   "source": [
    "# Stage 7: Split Dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "364cc7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(X, y, size):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbd10845",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = dataset_split(X, y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053d683",
   "metadata": {},
   "source": [
    "# Stage 8: Model Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d5ba132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_model(X_train, X_test, y_train, y_test, itera):\n",
    "    \n",
    "    model = LogisticRegression(max_iter=itera)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred)*100)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c90819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.51666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85      6093\n",
      "     neutral       0.83      0.95      0.89      5935\n",
      "    positive       0.90      0.81      0.86      5972\n",
      "\n",
      "    accuracy                           0.87     18000\n",
      "   macro avg       0.87      0.87      0.86     18000\n",
      "weighted avg       0.87      0.87      0.86     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = logistic_model(X_train, X_test, y_train, y_test, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6745b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred)*100)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "331f5199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.06111111111112\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.80      0.75      6093\n",
      "     neutral       0.80      0.75      0.77      5935\n",
      "    positive       0.78      0.73      0.75      5972\n",
      "\n",
      "    accuracy                           0.76     18000\n",
      "   macro avg       0.76      0.76      0.76     18000\n",
      "weighted avg       0.76      0.76      0.76     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = naive_bayes_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f342aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred)*100)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "576b73f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.82777777777778\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86      6093\n",
      "     neutral       0.85      0.96      0.90      5935\n",
      "    positive       0.91      0.83      0.86      5972\n",
      "\n",
      "    accuracy                           0.88     18000\n",
      "   macro avg       0.88      0.88      0.88     18000\n",
      "weighted avg       0.88      0.88      0.88     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = support_vector_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad05b53",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d8effef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_analysis_svm_model.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model\n",
    "# joblib.dump(lr_model, 'sentiment_analysis_lr_model.pkl')\n",
    "# joblib.dump(nb_model, 'sentiment_analysis_nb_model.pkl')\n",
    "joblib.dump(svm_model, 'sentiment_analysis_svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3cdf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    \n",
    "    model = joblib.load('sentiment_analysis_svm_model.pkl')\n",
    "    vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "    X = vectorizer.transform([text])\n",
    "    y_pred = model.predict(X)[0]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92f81522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: 1.0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Not me giggling everytime he says 'balls' Anyways, great vid man!!\"\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Predicted sentiment:\", predict(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e2e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
